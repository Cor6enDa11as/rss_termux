#!/usr/bin/env python3
"""
üöÄ RSS to Telegram Bot (Termux Optimized)
"""

import os
import json
import feedparser
import requests
import time
import logging
import random
from datetime import datetime, timezone, timedelta
#from dotenv import load_dotenv
from urllib.parse import urlparse

# ==================== –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ ====================
#load_dotenv()
#BOT_TOKEN = os.getenv('BOT_TOKEN')
#CHANNEL_ID = os.getenv('CHANNEL_ID')

#if not BOT_TOKEN or not CHANNEL_ID:
#    logging.error("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ BOT_TOKEN –∏ CHANNEL_ID –≤ .env —Ñ–∞–π–ª–µ!")
#    exit(1)

# ‚úÖ –¢–ï–†–ú–ò–ù–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò TERMUX
CONFIG = {
    'REQUEST_DELAY_MIN': int(os.getenv('REQUEST_DELAY_MIN', '8')),
    'REQUEST_DELAY_MAX': int(os.getenv('REQUEST_DELAY_MAX', '20')),
    'MAX_HOURS_BACK': int(os.getenv('MAX_HOURS_BACK', '4'))
}

# ==================== –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler('bot.log'), logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# ==================== –§—É–Ω–∫—Ü–∏–∏ ====================

def load_rss_feeds():
    """üì∞ –ó–∞–≥—Ä—É–∂–∞–µ—Ç RSS-–ª–µ–Ω—Ç—ã –∏ —Ö—ç—à—Ç–µ–≥–∏"""
    feeds = []
    hashtags = {}
    
    try:
        with open('feeds.txt', 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                if '#' in line:
                    url, tag = line.split('#', 1)
                    feeds.append(url.strip())
                    hashtags[url.strip()] = '#' + tag.strip()
                else:
                    feeds.append(line)
                    hashtags[line] = '#–Ω–æ–≤–æ—Å—Ç–∏'
    
    except FileNotFoundError:
        logger.error("‚ùå –§–∞–π–ª feeds.txt –Ω–µ –Ω–∞–π–¥–µ–Ω")
        exit(1)
    
    if not feeds:
        logger.error("‚ùå –ù–µ—Ç RSS-–ª–µ–Ω—Ç")
        exit(1)
    
    logger.info(f"üì∞ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(feeds)} –ª–µ–Ω—Ç")
    return feeds, hashtags

def load_dates():
    """üìÅ –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤"""
    try:
        with open('dates.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
            for url, info in data.items():
                if 'last_date' in info:
                    info['last_date'] = datetime.fromisoformat(info['last_date'])
            return data
    except FileNotFoundError:
        return {}

def save_dates(dates_dict):
    """üíæ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤"""
    data_to_save = {}
    for url, info in dates_dict.items():
        if isinstance(info, dict) and 'last_date' in info:
            data_to_save[url] = {'last_date': info['last_date'].isoformat()}
    
    with open('dates.json', 'w', encoding='utf-8') as f:
        json.dump(data_to_save, f, indent=2, ensure_ascii=False)

def send_to_telegram(title, link, feed_url, hashtags_dict, entry):
    """üì® –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ (–ü–†–ï–í–¨–Æ –°–í–ï–†–•–£!)"""
    try:
        clean_title = title.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        hashtag = hashtags_dict.get(feed_url, '#–Ω–æ–≤–æ—Å—Ç–∏')
        
        author = getattr(entry, 'author', '')
        if author:
            author_hashtag = author.replace(" ", "")
            message = f'<a href="{link}">{clean_title}</a>\n\nüìå {hashtag} üë§ #{author_hashtag}'
        else:
            message = f'<a href="{link}">{clean_title}</a>\n\nüìå {hashtag}'

        data = {
            'chat_id': CHANNEL_ID,
            'text': message,
            'parse_mode': 'HTML',
            'link_preview_options': json.dumps({
                'is_disabled': False,
                'url': link,
                'show_above_text': True
            })
        }

        response = requests.post(f'https://api.telegram.org/bot{BOT_TOKEN}/sendMessage',
                               data=data, timeout=10)
        
        if response.status_code == 200:
            time.sleep(random.uniform(20, 30))
            return True
        else:
            logger.error(f"‚ùå TG –æ—Ç–≤–µ—Ç: {response.status_code}")
            return False
        
    except Exception as e:
        logger.error(f"ü§ñ –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
        return False

def parse_feed(url):
    """üì∞ –ü–∞—Ä—Å–∏—Ç RSS-–ª–µ–Ω—Ç—É"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0', 'Accept': 'application/rss+xml'}
        response = requests.get(url, headers=headers, timeout=10)
        feed = feedparser.parse(response.content)
        return feed if hasattr(feed, 'entries') and feed.entries else None
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url[:40]}...: {e}")
        return None

def get_entry_date(entry):
    """üìÖ –ü–æ–ª—É—á–∞–µ—Ç –¥–∞—Ç—É –∑–∞–ø–∏—Å–∏"""
    if hasattr(entry, 'published_parsed') and entry.published_parsed:
        return datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
    return datetime.now(timezone.utc)

# ==================== –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ====================

def check_feeds():
    """üîç –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ª–µ–Ω—Ç"""
    logger.info("=" * 60)
    logger.info(f"ü§ñ [{len(RSS_FEEDS)} –ª–µ–Ω—Ç] {datetime.now().strftime('%H:%M')}")
    start_time = time.time()

    dates = load_dates()
    sent_count = 0

    for feed_url in RSS_FEEDS:
        try:
            logger.info(f"üì∞ –ü—Ä–æ–≤–µ—Ä–∫–∞: {feed_url[:50]}...")
            
            last_date = dates.get(feed_url, {}).get('last_date')
            threshold_date = (datetime.now(timezone.utc) - timedelta(hours=CONFIG['MAX_HOURS_BACK']) 
                            if last_date is None else last_date)

            feed = parse_feed(feed_url)
            if not feed:
                time.sleep(random.uniform(CONFIG['REQUEST_DELAY_MIN'], CONFIG['REQUEST_DELAY_MAX']))
                continue

            new_entries = []
            for entry in feed.entries:
                entry_date = get_entry_date(entry)
                if entry_date > threshold_date:
                    new_entries.append((entry, entry_date))

            if new_entries:
                logger.info(f"  üì¶ –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö: {len(new_entries)}")
                new_entries.sort(key=lambda x: x[1])

                for entry, pub_date in new_entries:
                    title = getattr(entry, 'title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                    link = getattr(entry, 'link', '')
                    
                    if not link:
                        continue

                    logger.info(f"  üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ [{pub_date.strftime('%H:%M')}]: {title[:60]}...")
                    
                    if send_to_telegram(title, link, feed_url, HASHTAGS, entry):
                        sent_count += 1
                        dates[feed_url] = {'last_date': pub_date}
                        save_dates(dates)
                    else:
                        logger.error("  ‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏")
                        break
            else:
                logger.info(f"  ‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")

            time.sleep(random.uniform(CONFIG['REQUEST_DELAY_MIN'], CONFIG['REQUEST_DELAY_MAX']))

        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
            time.sleep(random.uniform(CONFIG['REQUEST_DELAY_MIN'], CONFIG['REQUEST_DELAY_MAX']))
            continue

    save_dates(dates)
    logger.info(f"üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent_count} –Ω–æ–≤–æ—Å—Ç–µ–π")
    logger.info(f"‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {time.time() - start_time:.1f} —Å–µ–∫")
    logger.info("=" * 60)
    return sent_count

# ==================== –ó–∞–ø—É—Å–∫ ====================

if __name__ == '__main__':
    logger.info("=" * 60)
    RSS_FEEDS, HASHTAGS = load_rss_feeds()
    logger.info(f"‚è∞ –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: {CONFIG['REQUEST_DELAY_MIN']}-{CONFIG['REQUEST_DELAY_MAX']} —Å–µ–∫")
    logger.info(f"‚è≥ –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞: {CONFIG['MAX_HOURS_BACK']} —á–∞—Å–æ–≤")
    logger.info("=" * 60)
    
    sent_count = check_feeds()
    logger.info(f"‚úÖ –ë–æ—Ç –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É. –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent_count} –ø–æ—Å—Ç–æ–≤")
